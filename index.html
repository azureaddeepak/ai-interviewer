<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>AI Interviewer (Azure DevOps + AKS)</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      text-align: center;
      padding: 50px;
      background-color: #f7f9fc;
    }
    button {
      font-size: 16px;
      padding: 12px 24px;
      margin: 10px;
      border: none;
      border-radius: 5px;
      background: #0078d4;
      color: white;
      cursor: pointer;
    }
    button:disabled { opacity: 0.5; }
    .section { margin: 30px; }
    audio { margin: 10px; }
    #status { margin: 20px; font-style: italic; color: #666; }
    #recording-timer { font-weight: bold; color: red; }
  </style>
</head>
<body>

  <h1>ü§ñ AI Interviewer (Azure DevOps + AKS)</h1>
  <p id="question">Press "Start Interview" to begin.</p>
  <div class="section">
    <button id="startBtn">üü¢ Start Interview</button>
  </div>
  <div id="status">Ready when you are.</div>
  <div id="recordings"></div>

  <script>
    const questions = [
      "Welcome! Please tell me about your experience with Azure DevOps and CI/CD pipelines.",
      "Have you used Terraform or ARM templates? Describe your experience.",
      "Tell me about a time you fixed a broken deployment pipeline.",
      "How do you manage secrets in Azure DevOps? Have you used Key Vault?",
      "Explain how you deploy applications to Azure Kubernetes Service (AKS).",
      "What tools do you use for monitoring and logging in AKS?",
      "Describe your experience with Helm charts in AKS deployments."
    ];

    let currentQ = 0;
    const synth = window.speechSynthesis;
    const startBtn = document.getElementById("startBtn");
    const questionEl = document.getElementById("question");
    const statusEl = document.getElementById("status");
    const recordingsEl = document.getElementById("recordings");

    // Text-to-Speech
    function speak(text) {
      const utter = new SpeechSynthesisUtterance(text);
      utter.rate = 0.9;
      synth.speak(utter);
    }

    // Start Interview
    startBtn.onclick = () => {
      startBtn.disabled = true;
      statusEl.textContent = "üéôÔ∏è Starting interview...";
      setTimeout(() => {
        nextQuestion();
      }, 1000);
    };

    // Move to next question (auto)
    function nextQuestion() {
      if (currentQ >= questions.length) {
        questionEl.textContent = "‚úÖ Interview complete! Thank you.";
        statusEl.textContent = "All questions completed.";
        return;
      }

      const q = questions[currentQ];
      questionEl.textContent = `Question ${currentQ + 1}: ${q}`;
      speak(q);
      statusEl.textContent = "‚è±Ô∏è You have 40 seconds to answer.";

      // Start recording after 3 seconds
      setTimeout(startRecording, 3000);
    }

    // Start Recording (Auto)
    function startRecording() {
      const timerDisplay = document.createElement('div');
      timerDisplay.id = 'recording-timer';
      timerDisplay.innerHTML = '<strong>‚è±Ô∏è 40</strong>';
      statusEl.appendChild(timerDisplay);

      let seconds = 40;
      const countdown = setInterval(() => {
        seconds--;
        timerDisplay.innerHTML = `<strong>‚è±Ô∏è ${seconds}</strong>`;
        if (seconds <= 0) {
          clearInterval(countdown);
          timerDisplay.remove();
          statusEl.textContent = "‚úÖ Answer recorded. Moving to next question...";
          currentQ++;
          setTimeout(nextQuestion, 1000);
        }
      }, 1000);

      // Record audio
      navigator.mediaDevices.getUserMedia({ audio: true })
        .then(stream => {
          const mediaRecorder = new MediaRecorder(stream);
          const audioChunks = [];

          mediaRecorder.ondataavailable = event => {
            audioChunks.push(event.data);
          };

          mediaRecorder.onstop = () => {
            const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
            const audioURL = URL.createObjectURL(audioBlob);

            const audio = document.createElement('audio');
            audio.src = audioURL;
            audio.controls = true;

            const p = document.createElement('p');
            p.innerHTML = `<strong>Q${currentQ + 1}:</strong> ${questions[currentQ]}`;
            recordingsEl.appendChild(p);
            recordingsEl.appendChild(audio);
          };

          mediaRecorder.start();
          setTimeout(() => {
            mediaRecorder.stop();
            stream.getTracks().forEach(track => track.stop());
          }, 40000); // Stop after 40 seconds
        })
        .catch(err => {
          statusEl.textContent = "Error: " + err.message;
        });
    }
  </script>
</body>
</html>
